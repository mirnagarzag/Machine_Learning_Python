{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0814952e",
   "metadata": {},
   "source": [
    "# A1 Classification Model Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6a478f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import pandas            as pd                       \n",
    "import matplotlib.pyplot as plt                      \n",
    "import seaborn           as sns                      \n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.linear_model import LogisticRegression  \n",
    "import statsmodels.formula.api as smf                \n",
    "from sklearn.metrics import confusion_matrix         \n",
    "from sklearn.metrics import roc_auc_score            \n",
    "from sklearn.neighbors import KNeighborsClassifier   \n",
    "from sklearn.neighbors import KNeighborsRegressor    \n",
    "from sklearn.preprocessing import StandardScaler     \n",
    "from sklearn.tree import DecisionTreeClassifier      \n",
    "from sklearn.tree import plot_tree  \n",
    "from sklearn.ensemble import RandomForestClassifier     \n",
    "from sklearn.ensemble import GradientBoostingClassifier \n",
    "from sklearn.model_selection import RandomizedSearchCV     \n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "\n",
    "#loading data\n",
    "file = \"./GOT_character_predictions.xlsx\"\n",
    "got = pd.read_excel(io = file)\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "\n",
    "\n",
    "got.head(n = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc637df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "got.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae80941",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a copy of the dataframe\n",
    "got_2 = pd.DataFrame.copy(got)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c6019a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the correlation of the variables\n",
    "got_corr = got.corr(method = 'pearson').round(decimals = 2)\n",
    "got_corr['isAlive'].sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0844628b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#flagging missing values\n",
    "\n",
    "for col in got_2:\n",
    "    if got_2[col].isnull().astype(int).sum() > 0:\n",
    "        got_2['m_'+col] = got_2[col].isnull().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a107ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "got_2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded0754e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output the original balance between those that survived and those that did not survive\n",
    "got_2.loc[: , 'isAlive'].value_counts(normalize = True).round(decimals = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1d9665",
   "metadata": {},
   "outputs": [],
   "source": [
    "placeholder_lst = []\n",
    "\n",
    "# creating a loop over each name\n",
    "for index, col in got_2.iterrows():\n",
    "    \n",
    "    # splitting name by space\n",
    "    split_name = got_2.loc[index, 'name'].split(sep = ' ')\n",
    "    placeholder_lst.append(split_name)\n",
    "    \n",
    "\n",
    "# converting placeholder_lst into a DataFrame \n",
    "name_df = pd.DataFrame(placeholder_lst)\n",
    "\n",
    "#rename of the columns\n",
    "name_df.columns = ['f_name','l_name','name_3','name_4','name_5','name_6']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0322d97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f472cec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#attaching the new df to the got df\n",
    "got_2 = pd.concat([got_2, name_df],\n",
    "                 axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba1d5e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# guessing gender based on (given) name\n",
    "#import gender_guesser.detector as gender \n",
    "# placeholder list\n",
    "#placeholder_lst = []\n",
    "\n",
    "\n",
    "# looping to guess gender\n",
    "#for name in got_2['f_name']:\n",
    "#    guess = gender.Detector().get_gender(name)\n",
    "#    print(guess)\n",
    "#    placeholder_lst.append(guess)\n",
    "\n",
    "\n",
    "# converting list into a series\n",
    "#got_2['gender'] = pd.Series(placeholder_lst)\n",
    "\n",
    "\n",
    "# checking results\n",
    "#got_2.head(n = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4c6fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a list with the results of the gender guesser\n",
    "gender_guess_got = ['unknown', 'unknown', 'andy', 'unknown', 'female', 'unknown', 'unknown', 'unknown', \n",
    "                    'male', 'male', 'mostly_male', 'mostly_male', 'mostly_male', 'mostly_male', 'mostly_male',\n",
    "                    'mostly_male', 'unknown', 'male', 'unknown', 'unknown', 'male', 'male', 'female', 'unknown',\n",
    "                    'unknown', 'female', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', \n",
    "                    'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown',\n",
    "                    'unknown', 'mostly_female', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', \n",
    "                    'female', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown',\n",
    "                    'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown',\n",
    "                    'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', \n",
    "                    'female', 'unknown', 'unknown', 'unknown', 'male', 'male', 'andy', 'andy', 'unknown',\n",
    "                    'andy', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', \n",
    "                    'unknown', 'unknown', 'unknown', 'female', 'male', 'male', 'unknown', 'male', 'male',\n",
    "                    'male', 'male', 'male', 'male', 'male', 'mostly_male', 'male', 'mostly_male', 'mostly_male',\n",
    "                    'unknown', 'unknown', 'unknown', 'male', 'unknown', 'male', 'unknown', 'male',                     'unknown', 'male', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown',                     'unknown', 'unknown', 'unknown', 'female', 'unknown', 'mostly_male', 'unknown', 'unknown',                    'male', 'female', 'andy', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown',                   'unknown', 'unknown', 'unknown', 'mostly_male', 'unknown', 'unknown', 'unknown', 'unknown',                  'unknown', 'unknown', 'female', 'unknown', 'female', 'unknown', 'unknown', 'unknown',                     'unknown', 'unknown', 'male', 'mostly_female', 'unknown', 'unknown', 'unknown', 'unknown',                    'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown',                    'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'andy', 'female', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'male', 'male', 'unknown', 'unknown', 'unknown', 'male', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'male', 'female', 'female', 'female', 'female', 'female', 'female', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'unknown', 'mostly_female', 'female', 'unknown', 'mostly_female', 'unknown', 'female', 'unknown', 'female', 'unknown', 'male', 'male', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'male', 'unknown', 'andy', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'unknown', 'unknown', 'unknown', 'female', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'male', 'male', 'male', 'male', 'male', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'female', 'female', 'female', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'male', 'male', 'male', 'male', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'mostly_female', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'male', 'male', 'male', 'unknown', 'male', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'mostly_male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'mostly_male', 'female', 'male', 'male', 'male', 'female', 'unknown', 'unknown', 'female', 'unknown', 'unknown', 'male', 'male', 'male', 'female', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'unknown', 'unknown', 'unknown', 'female', 'unknown', 'andy', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'female', 'male', 'unknown', 'unknown', 'female', 'male', 'unknown', 'male', 'unknown', 'unknown', 'male', 'female', 'female', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'unknown', 'female', 'female', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'male', 'male', 'male', 'unknown', 'male', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'unknown', 'male', 'male', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'unknown', 'male', 'unknown', 'male', 'male', 'unknown', 'unknown', 'male', 'male', 'unknown', 'male', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'male', 'female', 'unknown', 'unknown', 'female', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'unknown', 'female', 'female', 'female', 'unknown', 'unknown', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'male', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'mostly_male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'mostly_female', 'mostly_female', 'mostly_female', 'unknown', 'female', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'female', 'male', 'male', 'male', 'male', 'unknown', 'female', 'female', 'female', 'unknown', 'mostly_male', 'unknown', 'unknown', 'male', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'male', 'male', 'female', 'male', 'female', 'unknown', 'unknown', 'female', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'male', 'male', 'unknown', 'unknown', 'female', 'unknown', 'female', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'male', 'male', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'female', 'unknown', 'male', 'unknown', 'unknown', 'mostly_female', 'male', 'female', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'male', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'male', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'female', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'male', 'unknown', 'male', 'male', 'female', 'mostly_female', 'female', 'mostly_female', 'mostly_female', 'mostly_female', 'mostly_female', 'mostly_female', 'mostly_female', 'unknown', 'unknown', 'female', 'female', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'female', 'unknown', 'male', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'female', 'unknown', 'female', 'unknown', 'unknown', 'female', 'female', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'male', 'male', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'male', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'female', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'male', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'unknown', 'female', 'unknown', 'unknown', 'male', 'male', 'male', 'male', 'male', 'unknown', 'unknown', 'unknown', 'male', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'female', 'mostly_male', 'unknown', 'female', 'male', 'male', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'male', 'male', 'male', 'male', 'male', 'unknown', 'unknown', 'male', 'male', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'male', 'male', 'unknown', 'male', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'male', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'female', 'unknown', 'male', 'male', 'male', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'female', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'male', 'female', 'unknown', 'female', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'male', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'male', 'unknown', 'unknown', 'male', 'unknown', 'female', 'unknown', 'unknown', 'unknown', 'mostly_male', 'male', 'unknown', 'unknown', 'male', 'male', 'male', 'unknown', 'female', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'unknown', 'female', 'female', 'female', 'male', 'male', 'unknown', 'unknown', 'unknown', 'male', 'male', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'unknown', 'unknown', 'unknown', 'female', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'female', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'male', 'unknown', 'male', 'unknown', 'female', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'male', 'male', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'male', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'male', 'unknown', 'male', 'male', 'andy', 'male', 'male', 'unknown', 'unknown', 'unknown', 'female', 'unknown', 'female', 'unknown', 'male', 'male', 'male', 'male', 'male', 'male', 'mostly_male', 'mostly_male', 'mostly_male', 'mostly_male', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'male', 'male', 'unknown', 'male', 'male', 'unknown', 'male', 'male', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'female', 'female', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'male', 'male', 'unknown', 'unknown', 'male', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'male', 'male', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'male', 'male', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'male', 'male', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'male', 'unknown', 'unknown', 'female', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'mostly_male', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'female', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'male', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'mostly_female', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'male', 'male', 'unknown', 'unknown', 'unknown', 'male', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'mostly_female', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'male', 'male', 'mostly_female', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'female', 'unknown', 'female', 'unknown', 'female', 'unknown', 'female', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'andy', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'female', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'unknown', 'unknown', 'unknown', 'mostly_female', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'male', 'male', 'male', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'male', 'female', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'unknown', 'unknown', 'unknown', 'male', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'male', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'unknown', 'female', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'female', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'male', 'unknown', 'male', 'male', 'unknown', 'male', 'unknown', 'male', 'male', 'male', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'female', 'unknown', 'unknown', 'unknown', 'male', 'male', 'male', 'male', 'male', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'female', 'unknown', 'unknown', 'unknown', 'female', 'unknown', 'unknown', 'unknown', 'mostly_male', 'male', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'male', 'male', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'mostly_female', 'unknown', 'unknown', 'unknown', 'female', 'male', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'female', 'male', 'mostly_male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'female', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89464d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concat gender to my df\n",
    "gender_df = pd.DataFrame(gender_guess_got)\n",
    "\n",
    "gender_df.columns = ['gender']\n",
    "got_2 = pd.concat([got_2,gender_df],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf6daf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "got_2.head(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775daad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filling median age in the NaN\n",
    "age_med = got_2['age'].median()\n",
    "got_2['age'].fillna(value = age_med, inplace = True)\n",
    "\n",
    "#filling Date of Birth\n",
    "date_of_birth_med = got_2['dateOfBirth'].median()\n",
    "got_2['dateOfBirth'].fillna(value = date_of_birth_med, inplace = True )\n",
    "got_2['age_mod'] = got_2['dateOfBirth']+got_2['age']\n",
    "\n",
    "#filling categorical values\n",
    "got_2['isAliveMother'].fillna(value = 0, inplace = True)\n",
    "got_2['isAliveFather'].fillna(value = 0, inplace = True)\n",
    "got_2['isAliveHeir'].fillna(value = 0, inplace = True)\n",
    "got_2['isAliveSpouse'].fillna(value = 0, inplace = True)\n",
    "\n",
    "#filling missing value variables\n",
    "got_2['title'].fillna(value = \"unknown\", inplace = True)\n",
    "got_2['mother'].fillna(value = \"unknown\", inplace = True)\n",
    "got_2['father'].fillna(value = \"unknown\", inplace = True)\n",
    "got_2['heir'].fillna(value = \"unknown\", inplace = True)\n",
    "got_2['spouse'].fillna(value = \"unknown\", inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2750ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting gender into female and male\n",
    "for index, col in got_2.iterrows():\n",
    "    if got_2.loc[index,'gender'] == 'mostly_female':\n",
    "        got_2.loc[index,'gender'] = 'female'\n",
    "    elif got_2.loc[index,'gender']== 'mostly_male':\n",
    "        got_2.loc[index,'gender'] = 'male'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf43a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating dummies for the gender row\n",
    "gen_dum = pd.get_dummies(got_2[\"gender\"])\n",
    "got_2 = got_2.join([gen_dum])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e517ac1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "got_2.head(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e90a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grouping the houses \n",
    "got_2['house_2'] = 0\n",
    "\n",
    "for row, col in got_2.iterrows():\n",
    "    if got_2.loc[row,'l_name'] =='Stark' or got_2.loc[row,'name_3']== 'Stark':\n",
    "        got_2.loc[row,'house_2'] = 'Stark'\n",
    "    elif got_2.loc[row,'l_name'] =='Frey' or got_2.loc[row,'name_3']== 'Frey':\n",
    "        got_2.loc[row,'house_2'] = 'Frey'\n",
    "    elif got_2.loc[row,'l_name'] =='Greyjoy' or got_2.loc[row,'name_3']== 'Greyjoy':\n",
    "        got_2.loc[row,'house_2'] = 'Greyjoy'  \n",
    "    elif got_2.loc[row,'l_name'] =='Lannister' or got_2.loc[row,'name_3']== 'Lannister':\n",
    "        got_2.loc[row,'house_2'] = 'Lannister' \n",
    "    elif got_2.loc[row,'l_name'] =='Targaryen' or got_2.loc[row,'name_3']== 'Targaryen':\n",
    "        got_2.loc[row,'house_2'] = 'Targaryen' \n",
    "    else:\n",
    "        got_2.loc[row,'house_2'] = 'Other'\n",
    "        \n",
    "#creating dummies for the houses\n",
    "got_2['House_Stark'] = 0\n",
    "for row,col in got_2.iterrows():\n",
    "    if got_2.loc[row, 'house_2'] == 'Stark':\n",
    "        got_2.loc[row,'House_Stark'] = 1\n",
    "    else:\n",
    "        got_2.loc[row, 'House_Stark'] = 0\n",
    "        \n",
    "got_2['House_Frey'] = 0\n",
    "for row,col in got_2.iterrows():\n",
    "    if got_2.loc[row, 'house_2'] == 'Frey':\n",
    "        got_2.loc[row,'House_Frey'] = 1\n",
    "    else:\n",
    "        got_2.loc[row, 'House_Frey'] = 0\n",
    "\n",
    "got_2['House_Greyjoy'] = 0\n",
    "for row,col in got_2.iterrows():\n",
    "    if got_2.loc[row, 'house_2'] == 'Greyjoy':\n",
    "        got_2.loc[row,'House_Greyjoy'] = 1\n",
    "    else:\n",
    "        got_2.loc[row, 'House_Greyjoy'] = 0\n",
    "\n",
    "got_2['House_Lannister'] = 0\n",
    "for row,col in got_2.iterrows():\n",
    "    if got_2.loc[row, 'house_2'] == 'Lannister':\n",
    "        got_2.loc[row,'House_Lannister'] = 1\n",
    "    else:\n",
    "        got_2.loc[row, 'House_Lannister'] = 0\n",
    "        \n",
    "got_2['House_Targaryen'] = 0\n",
    "for row,col in got_2.iterrows():\n",
    "    if got_2.loc[row, 'house_2'] == 'Targaryen':\n",
    "        got_2.loc[row,'House_Targaryen'] = 1\n",
    "    else:\n",
    "        got_2.loc[row, 'House_Targaryen'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0308307f",
   "metadata": {},
   "outputs": [],
   "source": [
    "got_2.head(n = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb3a853",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the correlation of the variables\n",
    "got_2_corr = got_2.corr(method = 'pearson').round(decimals = 2)\n",
    "got_2_corr['isAlive'].sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b1d87b",
   "metadata": {},
   "source": [
    "## 1 Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76435771",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train/test split with the dependent and independent variables\n",
    "got_2_data = got_2.loc[ : , ['book4_A_Feast_For_Crows','popularity','isMarried',\n",
    "                             'House_Frey','book1_A_Game_Of_Thrones','numDeadRelations',\n",
    "                             'House_Lannister', 'male','age_mod']]\n",
    "got_2_target = got_2.loc[ : , 'isAlive']\n",
    "\n",
    "\n",
    "# splitting the model\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "            got_2_data,\n",
    "            got_2_target,\n",
    "            random_state = 219,\n",
    "            test_size    = 0.10,\n",
    "            stratify     = got_2_target)\n",
    "\n",
    "\n",
    "# Instantiating a logistic regression model\n",
    "logreg = LogisticRegression(solver = 'lbfgs',\n",
    "                            C = 1,\n",
    "                            random_state = 219)\n",
    "logreg_fit = logreg.fit(x_train, y_train)\n",
    "logreg_pred = logreg_fit.predict(x_test)\n",
    "\n",
    "print('LogReg Training ACCURACY:', logreg_fit.score(x_train, y_train).round(4))\n",
    "print('LogReg Testing  ACCURACY:', logreg_fit.score(x_test, y_test).round(4))\n",
    "\n",
    "\n",
    "# saving scoring data\n",
    "logreg_train_score = logreg_fit.score(x_train, y_train).round(4) \n",
    "logreg_test_score  = logreg_fit.score(x_test, y_test).round(4)   \n",
    "\n",
    "\n",
    "# displaying and saving the gap between training and testing\n",
    "print('LogReg Train-Test Gap   :', abs(logreg_train_score - logreg_test_score).round(4))\n",
    "logreg_test_gap = abs(logreg_train_score - logreg_test_score).round(4)\n",
    "\n",
    "#printing the AUC\n",
    "print('AUC Score               :', roc_auc_score(y_true  = y_test,\n",
    "                                          y_score = logreg_pred).round(4))\n",
    "# saving AUC score for future use\n",
    "logreg_auc_score = roc_auc_score(y_true  = y_test,\n",
    "                                 y_score = logreg_pred).round(decimals = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ff523f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unpacking the confusion matrix\n",
    "logreg_tn, \\\n",
    "logreg_fp, \\\n",
    "logreg_fn, \\\n",
    "logreg_tp = confusion_matrix(y_true = y_test, y_pred = logreg_pred).ravel()\n",
    "\n",
    "\n",
    "# printing the results\n",
    "print(f\"\"\"\n",
    "True Negatives : {logreg_tn}\n",
    "False Positives: {logreg_fp}\n",
    "False Negatives: {logreg_fn}\n",
    "True Positives : {logreg_tp}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c00f99",
   "metadata": {},
   "source": [
    "### 1.1 Logistic Regression with Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f9642e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# declaring a hyperparameter space\n",
    "#C_range          = np.arange(0.1, 5.0, 0.1)\n",
    "#warm_start_range = [True, False]\n",
    "#solver_range     = ['newton-cg', 'sag', 'lbfgs']\n",
    "\n",
    "\n",
    "# creating a hyperparameter grid\n",
    "#param_grid = {'C'          : C_range,\n",
    "#              'warm_start' : warm_start_range,\n",
    "#              'solver'     : solver_range}\n",
    "\n",
    "\n",
    "# INSTANTIATING the model object without hyperparameters\n",
    "#lr_tuned = LogisticRegression(random_state = 219,\n",
    "#                              max_iter     = 1000) \n",
    "\n",
    "\n",
    "# GridSearchCV object\n",
    "#lr_tuned_cv = RandomizedSearchCV(estimator           = lr_tuned,   \n",
    "#                                 param_distributions = param_grid, \n",
    "#                                 cv                  = 3,          \n",
    "#                                 n_iter              = 250,        \n",
    "#                                 random_state        = 219,        \n",
    "#                                 scoring = make_scorer(\n",
    "#                                           roc_auc_score,\n",
    "#                                           needs_threshold = False)) \n",
    "\n",
    "\n",
    "# FITTING to the FULL DATASET (due to cross-validation)\n",
    "#lr_tuned_cv.fit(got_2_data, got_2_target)\n",
    "\n",
    "# printing the optimal parameters and best score\n",
    "#print(\"Tuned Parameters  :\", lr_tuned_cv.best_params_)\n",
    "#print(\"Tuned CV AUC      :\", lr_tuned_cv.best_score_.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe560b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# building a model based on hyperparameter tuning results\n",
    "\n",
    "lr_tuned = LogisticRegression(C            = 4.3999999999999995,\n",
    "                              warm_start   = True,\n",
    "                              solver       = 'lbfgs',\n",
    "                              max_iter     = 1000,\n",
    "                              random_state = 219)\n",
    "\n",
    "lr_tuned.fit(got_2_data, got_2_target)\n",
    "lr_tuned_pred = lr_tuned.predict(x_test)\n",
    "\n",
    "\n",
    "# SCORING the results\n",
    "print('LR Tuned Training ACCURACY:', lr_tuned.score(x_train, y_train).round(4))\n",
    "print('LR Tuned Testing  ACCURACY:', lr_tuned.score(x_test, y_test).round(4))\n",
    "print('LR Tuned AUC Score        :', roc_auc_score(y_true  = y_test,\n",
    "                                          y_score = lr_tuned_pred).round(4))\n",
    "# saving scoring data for future use\n",
    "lr_tuned_train_score = lr_tuned.score(x_train, y_train).round(4) \n",
    "lr_tuned_test_score  = lr_tuned.score(x_test, y_test).round(4)\n",
    "\n",
    "print('LR Train-Test Gap         :', abs(lr_tuned_train_score - lr_tuned_test_score).round(4))\n",
    "logreg_test_gap = abs(lr_tuned_train_score - lr_tuned_test_score).round(4)\n",
    "\n",
    "# saving the AUC score\n",
    "lr_tuned_auc         = roc_auc_score(y_true  = y_test,\n",
    "                                     y_score = lr_tuned_pred).round(4) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c3ce12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unpacking the confusion matrix\n",
    "lr_tuned_tn, \\\n",
    "lr_tuned_fp, \\\n",
    "lr_tuned_fn, \\\n",
    "lr_tuned_tp = confusion_matrix(y_true = y_test, y_pred = lr_tuned_pred).ravel()\n",
    "\n",
    "\n",
    "# printing the results\n",
    "print(f\"\"\"\n",
    "True Negatives : {lr_tuned_tn}\n",
    "False Positives: {lr_tuned_fp}\n",
    "False Negatives: {lr_tuned_fn}\n",
    "True Positives : {lr_tuned_tp}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707f7852",
   "metadata": {},
   "source": [
    "## 2 Full Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198b073c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiating a classification tree object\n",
    "full_tree = DecisionTreeClassifier()\n",
    "\n",
    "full_tree_fit = full_tree.fit(x_train, y_train)\n",
    "\n",
    "full_tree_pred = full_tree_fit.predict(x_test)\n",
    "\n",
    "\n",
    "# SCORING the model\n",
    "print('Full Tree Training ACCURACY:', full_tree_fit.score(x_train,\n",
    "                                                     y_train).round(4))\n",
    "\n",
    "print('Full Tree Testing ACCURACY :', full_tree_fit.score(x_test,\n",
    "                                                     y_test).round(4))\n",
    "\n",
    "print('Full Tree AUC Score        :', roc_auc_score(y_true  = y_test,\n",
    "                                            y_score = full_tree_pred).round(4))\n",
    "\n",
    "\n",
    "# saving scoring data for future use\n",
    "full_tree_train_score = full_tree_fit.score(x_train, y_train).round(4) \n",
    "full_tree_test_score  = full_tree_fit.score(x_test, y_test).round(4)   \n",
    "\n",
    "# displaying and saving the gap between training and testing\n",
    "print('Full Tree Train-Test Gap   :', abs(full_tree_train_score - full_tree_test_score).round(4))\n",
    "full_tree_test_gap = abs(full_tree_train_score - full_tree_test_score).round(4)\n",
    "\n",
    "# saving AUC\n",
    "full_tree_auc_score   = roc_auc_score(y_true  = y_test,\n",
    "                                      y_score = full_tree_pred).round(4) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747aba35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unpacking the confusion matrix\n",
    "full_tree_tn, \\\n",
    "full_tree_fp, \\\n",
    "full_tree_fn, \\\n",
    "full_tree_tp = confusion_matrix(y_true = y_test, y_pred = full_tree_pred).ravel()\n",
    "\n",
    "\n",
    "# printing the results\n",
    "print(f\"\"\"\n",
    "True Negatives : {full_tree_tn}\n",
    "False Positives: {full_tree_fp}\n",
    "False Negatives: {full_tree_fn}\n",
    "True Positives : {full_tree_tp}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be9d185",
   "metadata": {},
   "source": [
    "### 2.1 Tree with Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cda312f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# declaring a hyperparameter space\n",
    "#criterion_range = ['gini', 'entropy']\n",
    "#splitter_range  = ['best', 'random']\n",
    "#depth_range     = np.arange(1, 25, 1)\n",
    "#leaf_range      = np.arange(1, 100, 1)\n",
    "\n",
    "\n",
    "# creating a hyperparameter grid\n",
    "#param_grid = {'criterion'        : criterion_range,\n",
    "#              'splitter'         : splitter_range,\n",
    "#              'max_depth'        : depth_range,\n",
    "#              'min_samples_leaf' : leaf_range}\n",
    "\n",
    "\n",
    "#tuned_tree = DecisionTreeClassifier(random_state = 219)\n",
    "\n",
    "\n",
    "# RandomizedSearchCV object\n",
    "#tuned_tree_cv = RandomizedSearchCV(estimator             = tuned_tree,\n",
    "#                                   param_distributions   = param_grid,\n",
    "#                                   cv                    = 3,\n",
    "#                                   n_iter                = 1000,\n",
    "#                                   random_state          = 219,\n",
    "#                                   scoring = make_scorer(roc_auc_score,\n",
    "#                                             needs_threshold = False))\n",
    "\n",
    "\n",
    "#tuned_tree_cv.fit(got_2_data, got_2_target)\n",
    "\n",
    "\n",
    "# printing the optimal parameters and best score\n",
    "#print(\"Tuned Parameters  :\", tuned_tree_cv.best_params_)\n",
    "#print(\"Tuned Training AUC:\", tuned_tree_cv.best_score_.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7aa5f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Istantiating a logistic regression model with tuned values\n",
    "tree_tuned = DecisionTreeClassifier(splitter         = 'best',\n",
    "                                    min_samples_leaf = 6,\n",
    "                                    max_depth        = 14,\n",
    "                                    criterion        = 'entropy',\n",
    "                                    random_state     = 219)\n",
    "\n",
    "tree_tuned_fit = tree_tuned.fit(got_2_data, got_2_target)\n",
    "\n",
    "tree_tuned_pred = tree_tuned.predict(x_test)\n",
    "\n",
    "\n",
    "# SCORING the results\n",
    "print('Training ACCURACY:', tree_tuned.score(x_train, y_train).round(4))\n",
    "print('Testing  ACCURACY:', tree_tuned.score(x_test, y_test).round(4))\n",
    "print('AUC Score        :', roc_auc_score(y_true  = y_test,\n",
    "                                          y_score = tree_tuned_pred).round(4))\n",
    "\n",
    "\n",
    "\n",
    "# saving scoring data for future use\n",
    "tree_tuned_train_score = tree_tuned.score(x_train, y_train).round(4) \n",
    "tree_tuned_test_score  = tree_tuned.score(x_test, y_test).round(4)   \n",
    "\n",
    "print('Tuned Tree Train-Test Gap   :', abs(tree_tuned_train_score - tree_tuned_test_score).round(4))\n",
    "tree_tuned_test_gap = abs(tree_tuned_train_score - tree_tuned_test_score).round(4)\n",
    "\n",
    "# saving the AUC score\n",
    "tree_tuned_auc         = roc_auc_score(y_true  = y_test,\n",
    "                                       y_score = tree_tuned_pred).round(4) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7264a2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unpacking the confusion matrix\n",
    "tuned_tree_tn, \\\n",
    "tuned_tree_fp, \\\n",
    "tuned_tree_fn, \\\n",
    "tuned_tree_tp = confusion_matrix(y_true = y_test, y_pred = tree_tuned_pred).ravel()\n",
    "\n",
    "\n",
    "# printing the results\n",
    "print(f\"\"\"\n",
    "True Negatives : {tuned_tree_tn}\n",
    "False Positives: {tuned_tree_fp}\n",
    "False Negatives: {tuned_tree_fn}\n",
    "True Positives : {tuned_tree_tp}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a21caac4",
   "metadata": {},
   "source": [
    "## 3 Pruned Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eda2c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiating a classification tree object\n",
    "pruned_tree = DecisionTreeClassifier(max_depth = 4,\n",
    "                                     min_samples_leaf = 25,\n",
    "                                     random_state = 219)\n",
    "\n",
    "\n",
    "pruned_tree_fit  = pruned_tree.fit(x_train, y_train)\n",
    "pruned_tree_pred = pruned_tree_fit.predict(x_test)\n",
    "\n",
    "\n",
    "# scoring the model\n",
    "print('Training ACCURACY:', pruned_tree_fit.score(x_train, y_train).round(4))\n",
    "print('Testing  ACCURACY:', pruned_tree_fit.score(x_test, y_test).round(4))\n",
    "\n",
    "\n",
    "# saving scoring data for future use\n",
    "pruned_tree_train_score = pruned_tree_fit.score(x_train, y_train).round(4) \n",
    "pruned_tree_test_score  = pruned_tree_fit.score(x_test, y_test).round(4)   \n",
    "\n",
    "print('Train-Test Gap   :', abs(pruned_tree_train_score - pruned_tree_test_score).round(4))\n",
    "pruned_tree_test_gap = abs(pruned_tree_train_score - pruned_tree_test_score).round(4)\n",
    "print('AUC Score        :', roc_auc_score(y_true  = y_test,\n",
    "                                          y_score = pruned_tree_pred).round(4))\n",
    "\n",
    "# saving auc score\n",
    "pruned_tree_auc_score   = roc_auc_score(y_true  = y_test,\n",
    "                                        y_score = pruned_tree_pred).round(4) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6279f1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unpacking the confusion matrix\n",
    "pruned_tree_tn, \\\n",
    "pruned_tree_fp, \\\n",
    "pruned_tree_fn, \\\n",
    "pruned_tree_tp = confusion_matrix(y_true = y_test, y_pred = pruned_tree_pred).ravel()\n",
    "\n",
    "\n",
    "# printing the results\n",
    "print(f\"\"\"\n",
    "True Negatives : {pruned_tree_tn}\n",
    "False Positives: {pruned_tree_fp}\n",
    "False Negatives: {pruned_tree_fn}\n",
    "True Positives : {pruned_tree_tp}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc741516",
   "metadata": {},
   "source": [
    "## 4 KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69d076b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimal_neighbors(x_data,\n",
    "                      y_data,\n",
    "                      standardize = True,\n",
    "                      pct_test=0.10,\n",
    "                      seed=219,\n",
    "                      response_type='class',\n",
    "                      max_neighbors=20,\n",
    "                      show_viz=True):    \n",
    "    \n",
    "    if standardize == True:\n",
    "        # optionally standardizing x_data\n",
    "        scaler             = StandardScaler()\n",
    "        scaler.fit(x_data)\n",
    "        x_scaled           = scaler.transform(x_data)\n",
    "        x_scaled_df        = pd.DataFrame(x_scaled)\n",
    "        x_data             = x_scaled_df\n",
    "\n",
    "\n",
    "\n",
    "    # train-test split\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x_data,\n",
    "                                                        y_data,\n",
    "                                                        test_size = pct_test,\n",
    "                                                        random_state = seed)\n",
    "    # creating lists for training set accuracy and test set accuracy\n",
    "    training_accuracy = []\n",
    "    test_accuracy = []\n",
    "        \n",
    "    # setting neighbor range\n",
    "    neighbors_settings = range(1, max_neighbors + 1)\n",
    "\n",
    "    for n_neighbors in neighbors_settings:\n",
    "        # building the model based on response variable type\n",
    "        if response_type == 'reg':\n",
    "            clf = KNeighborsRegressor(n_neighbors = n_neighbors)\n",
    "            clf.fit(x_train, y_train)\n",
    "            \n",
    "        elif response_type == 'class':\n",
    "            clf = KNeighborsClassifier(n_neighbors = n_neighbors)\n",
    "            clf.fit(x_train, y_train)            \n",
    "            \n",
    "        else:\n",
    "            print(\"Error: response_type must be 'reg' or 'class'\")\n",
    "        \n",
    "        \n",
    "        # recording the training set accuracy\n",
    "        training_accuracy.append(clf.score(x_train, y_train))\n",
    "    \n",
    "        # recording the generalization accuracy\n",
    "        test_accuracy.append(clf.score(x_test, y_test))\n",
    "    \n",
    "    # returning optimal number of neighbors\n",
    "    print(f\"The optimal number of neighbors is: {test_accuracy.index(max(test_accuracy))+1}\")\n",
    "    return test_accuracy.index(max(test_accuracy))+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845298cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# determining the optimal number of neighbors\n",
    "opt_neighbors = optimal_neighbors(x_data        = got_2_data,\n",
    "                                  y_data        = got_2_target,\n",
    "                                  response_type = 'class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd923642",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiating StandardScaler()\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scaler.fit(got_2_data)\n",
    "\n",
    "x_scaled     = scaler.transform(got_2_data)\n",
    "\n",
    "\n",
    "# converting to a DataFrame\n",
    "x_scaled_df  = pd.DataFrame(x_scaled) \n",
    "\n",
    "\n",
    "# train-test split with the scaled data\n",
    "x_train_scaled, x_test_scaled, y_train_scaled, y_test_scaled = train_test_split(\n",
    "            x_scaled_df,\n",
    "            got_2_target,\n",
    "            random_state = 219,\n",
    "            test_size    = 0.1,\n",
    "            stratify     = got_2_target)\n",
    "\n",
    "\n",
    "# KNN classification model with optimal neighbors\n",
    "knn_opt = KNeighborsClassifier(n_neighbors = opt_neighbors)\n",
    "\n",
    "knn_fit = knn_opt.fit(x_train_scaled, y_train_scaled)\n",
    "\n",
    "knn_pred = knn_fit.predict(x_test_scaled)\n",
    "\n",
    "# SCORING the results\n",
    "print('Training ACCURACY:', knn_fit.score(x_train_scaled, y_train_scaled).round(4))\n",
    "print('Testing  ACCURACY:', knn_fit.score(x_test_scaled, y_test_scaled).round(4))\n",
    "\n",
    "\n",
    "# saving scoring data\n",
    "knn_train_score = knn_fit.score(x_train_scaled, y_train_scaled).round(4)\n",
    "knn_test_score  = knn_fit.score(x_test_scaled, y_test_scaled).round(4)\n",
    "\n",
    "print('Train-Test Gap   :', abs(knn_train_score - knn_test_score).round(4))\n",
    "knn_test_gap = abs(knn_train_score - knn_test_score).round(4)\n",
    "print('AUC Score        :', roc_auc_score(y_true  = y_test,\n",
    "                                          y_score = knn_pred).round(4))\n",
    "\n",
    "# saving AUC score\n",
    "knn_auc_score   = roc_auc_score(y_true  = y_test,\n",
    "                                          y_score = knn_pred).round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17e2683",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unpacking the confusion matrix\n",
    "knn_tree_tn, \\\n",
    "knn_tree_fp, \\\n",
    "knn_tree_fn, \\\n",
    "knn_tree_tp = confusion_matrix(y_true = y_test, y_pred = knn_pred).ravel()\n",
    "\n",
    "\n",
    "# printing each result one-by-one\n",
    "print(f\"\"\"\n",
    "True Negatives : {knn_tree_tn}\n",
    "False Positives: {knn_tree_fp}\n",
    "False Negatives: {knn_tree_fn}\n",
    "True Positives : {knn_tree_tp}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d52b0ea3",
   "metadata": {},
   "source": [
    "## 5 Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576ad07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSTANTIATING a random forest model with default values\n",
    "rf_default = RandomForestClassifier(n_estimators     = 100,\n",
    "                                    criterion        = 'gini',\n",
    "                                    max_depth        = 4,\n",
    "                                    min_samples_leaf = 1,\n",
    "                                    bootstrap        = True,\n",
    "                                    warm_start       = False,\n",
    "                                    random_state     = 219)\n",
    "# FITTING the training data\n",
    "rf_default_fit = rf_default.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "# PREDICTING based on the testing set\n",
    "rf_default_fit_pred = rf_default_fit.predict(x_test)\n",
    "\n",
    "\n",
    "# SCORING the results\n",
    "print('Training ACCURACY:', rf_default_fit.score(x_train, y_train).round(4))\n",
    "print('Testing  ACCURACY:', rf_default_fit.score(x_test, y_test).round(4))\n",
    "\n",
    "rf_train_score = rf_default_fit.score(x_train, y_train).round(4)\n",
    "rf_test_score  = rf_default_fit.score(x_test, y_test).round(4)\n",
    "\n",
    "print('Train-Test Gap   :', abs(rf_train_score - rf_test_score).round(4))\n",
    "rf_test_gap = abs(rf_train_score - rf_test_score).round(4)\n",
    "\n",
    "# saving AUC score\n",
    "print('AUC Score        :', roc_auc_score(y_true  = y_test,\n",
    "                                          y_score = rf_default_fit_pred).round(4))\n",
    "rf_auc_score   = roc_auc_score(y_true  = y_test,\n",
    "                                          y_score = rf_default_fit_pred).round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3975861c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unpacking the confusion matrix\n",
    "rf_tn, \\\n",
    "rf_fp, \\\n",
    "rf_fn, \\\n",
    "rf_tp = confusion_matrix(y_true = y_test, y_pred = rf_default_fit_pred).ravel()\n",
    "\n",
    "\n",
    "# printing each result one-by-one\n",
    "print(f\"\"\"\n",
    "True Negatives : {rf_tn}\n",
    "False Positives: {rf_fp}\n",
    "False Negatives: {rf_fn}\n",
    "True Positives : {rf_tp}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e034d71",
   "metadata": {},
   "source": [
    "### 5.1 Random Forest with Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d1c989",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FITTING the training data\n",
    "#rf_default_fit = rf_default.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "# PREDICTING based on the testing set\n",
    "#rf_default_fit_pred = rf_default_fit.predict(x_test)\n",
    "\n",
    "\n",
    "# declaring a hyperparameter space\n",
    "#estimator_range  = np.arange(100, 1100, 250)\n",
    "#leaf_range       = np.arange(1, 31, 10)\n",
    "#criterion_range  = ['gini', 'entropy']\n",
    "#bootstrap_range  = [True, False]\n",
    "#warm_start_range = [True, False]\n",
    "\n",
    "\n",
    "# creating a hyperparameter grid\n",
    "#param_grid = {'n_estimators'     : estimator_range,\n",
    "#              'min_samples_leaf' : leaf_range,\n",
    "#              'criterion'        : criterion_range,\n",
    "#              'bootstrap'        : bootstrap_range,\n",
    "#              'warm_start'       : warm_start_range}\n",
    "\n",
    "\n",
    "# INSTANTIATING the model object without hyperparameters\n",
    "#forest_grid = RandomForestClassifier(random_state = 219)\n",
    "\n",
    "\n",
    "# GridSearchCV object\n",
    "#forest_cv = RandomizedSearchCV(estimator           = forest_grid,\n",
    "#                               param_distributions = param_grid,\n",
    "#                               cv         = 3,\n",
    "#                               n_iter     = 1000,\n",
    "#                               scoring    = make_scorer(roc_auc_score,\n",
    "#                                            needs_threshold = False))\n",
    "\n",
    "\n",
    "# FITTING to the FULL DATASET (due to cross-validation)\n",
    "#forest_cv.fit(got_2_data,got_2_target)\n",
    "\n",
    "\n",
    "# PREDICT step is not needed\n",
    "\n",
    "\n",
    "# printing the optimal parameters and best score\n",
    "#print(\"Tuned Parameters  :\", forest_cv.best_params_)\n",
    "#print(\"Tuned Training AUC:\", forest_cv.best_score_.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38b605b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# INSTANTIATING with best_estimator\n",
    "forest_tuned = RandomForestClassifier(criterion        = 'entropy',\n",
    "                                      min_samples_leaf = 1,\n",
    "                                      n_estimators     = 350,\n",
    "                                      warm_start       = True,\n",
    "                                      bootstrap        = False,\n",
    "                                      random_state     = 219)\n",
    "\n",
    "\n",
    "# FITTING to the FULL DATASET (due to cross-validation)\n",
    "forest_tuned_fit = forest_tuned.fit(got_2_data, got_2_target)\n",
    "\n",
    "\n",
    "# PREDICTING based on the testing set\n",
    "forest_tuned_pred = forest_tuned_fit.predict(x_test)\n",
    "\n",
    "\n",
    "# SCORING the results\n",
    "print('Forest Tuned Training ACCURACY:', forest_tuned.score(x_train, y_train).round(4))\n",
    "print('Forest Tuned Testing  ACCURACY:', forest_tuned.score(x_test, y_test).round(4))\n",
    "print('Forest Tuned AUC Score        :', roc_auc_score(y_true  = y_test,\n",
    "                                                       y_score = forest_tuned_pred).round(4))\n",
    "\n",
    "\n",
    "# saving scoring data for future use\n",
    "forest_tuned_train_score = forest_tuned.score(x_train, y_train).round(4) # accuracy\n",
    "forest_tuned_test_score  = forest_tuned.score(x_test, y_test).round(4)   # accuracy\n",
    "\n",
    "print('Train-Test Gap                :', abs(forest_tuned_train_score - forest_tuned_test_score).round(4))\n",
    "forest_tuned_test_gap = abs(forest_tuned_train_score - forest_tuned_test_score).round(4)\n",
    "\n",
    "# saving the AUC score\n",
    "forest_tuned_auc = roc_auc_score(y_true  = y_test,\n",
    "                                 y_score = forest_tuned_pred).round(4) # auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dabb9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unpacking the confusion matrix\n",
    "tuned_rf_tn, \\\n",
    "tuned_rf_fp, \\\n",
    "tuned_rf_fn, \\\n",
    "tuned_rf_tp = confusion_matrix(y_true = y_test, y_pred = forest_tuned_pred).ravel()\n",
    "\n",
    "\n",
    "# printing each result one-by-one\n",
    "print(f\"\"\"\n",
    "True Negatives : {tuned_rf_tn}\n",
    "False Positives: {tuned_rf_fp}\n",
    "False Negatives: {tuned_rf_fn}\n",
    "True Positives : {tuned_rf_tp}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf40c8b",
   "metadata": {},
   "source": [
    "## 6 GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb13c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSTANTIATING the model object without hyperparameters\n",
    "full_gbm_default = GradientBoostingClassifier(loss          = 'deviance',\n",
    "                                              learning_rate = 0.1,\n",
    "                                              n_estimators  = 100,\n",
    "                                              criterion     = 'friedman_mse',\n",
    "                                              max_depth     = 4,\n",
    "                                              warm_start    = False,\n",
    "                                              random_state  = 219)\n",
    "\n",
    "\n",
    "# FIT step is needed as we are not using .best_estimator\n",
    "full_gbm_default_fit = full_gbm_default.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "# PREDICTING based on the testing set\n",
    "full_gbm_default_pred = full_gbm_default_fit.predict(x_test)\n",
    "\n",
    "\n",
    "# SCORING the results\n",
    "print('Training ACCURACY:', full_gbm_default_fit.score(x_train, y_train).round(4))\n",
    "print('Testing ACCURACY :', full_gbm_default_fit.score(x_test, y_test).round(4))\n",
    "\n",
    "gbm_train_acc = full_gbm_default_fit.score(x_train, y_train).round(4)\n",
    "gbm_test_acc  = full_gbm_default_fit.score(x_test, y_test).round(4)\n",
    "gbm_auc       = roc_auc_score(y_true  = y_test,\n",
    "                              y_score = full_gbm_default_pred).round(4)\n",
    "print('Train-Test Gap   :', abs(gbm_train_acc - gbm_test_acc).round(4))\n",
    "gbm_test_gap = abs(gbm_train_acc - gbm_test_acc).round(4)\n",
    "\n",
    "print('AUC Score        :', roc_auc_score(y_true  = y_test,\n",
    "                                          y_score = full_gbm_default_pred).round(4))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09d8129",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unpacking the confusion matrix\n",
    "gbm_default_tn, \\\n",
    "gbm_default_fp, \\\n",
    "gbm_default_fn, \\\n",
    "gbm_default_tp = confusion_matrix(y_true = y_test, y_pred = full_gbm_default_pred).ravel()\n",
    "\n",
    "\n",
    "# printing each result one-by-one\n",
    "print(f\"\"\"\n",
    "True Negatives : {gbm_default_tn}\n",
    "False Positives: {gbm_default_fp}\n",
    "False Negatives: {gbm_default_fn}\n",
    "True Positives : {gbm_default_tp}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aac778e",
   "metadata": {},
   "source": [
    "### 6.1 GBM with Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6ed0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# declaring a hyperparameter space\n",
    "#learn_range        = np.arange(0.1, 2.2, 0.5)\n",
    "#estimator_range    = np.arange(100, 501, 25)\n",
    "#depth_range        = np.arange(2, 11, 2)\n",
    "#warm_start_range   = [True, False]\n",
    "\n",
    "# creating a hyperparameter grid\n",
    "#param_grid = {'learning_rate' : learn_range,\n",
    "#              'max_depth'     : depth_range,\n",
    "#              'n_estimators'  : estimator_range,\n",
    "#              'warm_start'    : warm_start_range}\n",
    "\n",
    "\n",
    "# INSTANTIATING the model object without hyperparameters\n",
    "#full_gbm_grid = GradientBoostingClassifier(random_state = 219)\n",
    "\n",
    "\n",
    "# GridSearchCV object\n",
    "#full_gbm_cv = RandomizedSearchCV(estimator     = full_gbm_grid,\n",
    "#                           param_distributions = param_grid,\n",
    "#                           cv                  = 3,\n",
    "#                           n_iter              = 500,\n",
    "#                           random_state        = 219,\n",
    "#                           scoring             = make_scorer(roc_auc_score,\n",
    "#                                                 needs_threshold = False))\n",
    "\n",
    "\n",
    "# FITTING to the FULL DATASET (due to cross-validation)\n",
    "#full_gbm_cv.fit(got_2_data, got_2_target)\n",
    "\n",
    "# printing the optimal parameters and best score\n",
    "#print(\"Tuned Parameters  :\", full_gbm_cv.best_params_)\n",
    "#print(\"Tuned Training AUC:\", full_gbm_cv.best_score_.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d14ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSTANTIATING the model object without hyperparameters\n",
    "full_gbm_default = GradientBoostingClassifier(#loss          = 'deviance',\n",
    "                                              learning_rate = 0.1,\n",
    "                                              n_estimators  = 150,\n",
    "                                              #criterion     = 'friedman_mse',\n",
    "                                              max_depth     = 4,\n",
    "                                              warm_start    = False,\n",
    "                                              random_state  = 219)\n",
    "\n",
    "\n",
    "# FIT step is needed as we are not using .best_estimator\n",
    "full_gbm_default_fit = full_gbm_default.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "# PREDICTING based on the testing set\n",
    "full_gbm_default_pred = full_gbm_default_fit.predict(x_test)\n",
    "\n",
    "\n",
    "# SCORING the results\n",
    "print('Training ACCURACY:', full_gbm_default_fit.score(x_train, y_train).round(4))\n",
    "print('Testing ACCURACY :', full_gbm_default_fit.score(x_test, y_test).round(4))\n",
    "print('AUC Score        :', roc_auc_score(y_true  = y_test,\n",
    "                                          y_score = full_gbm_default_pred).round(4))\n",
    "\n",
    "# saving scoring data for future use\n",
    "gbm_tuned_train_score = full_gbm_default.score(x_train, y_train).round(4) # accuracy\n",
    "gbm_tuned_test_score  = full_gbm_default.score(x_test, y_test).round(4)   # accuracy\n",
    "\n",
    "print('Train-Test Gap   :', abs(gbm_tuned_train_score - gbm_tuned_test_score).round(4))\n",
    "gbm_tuned_test_gap = abs(gbm_tuned_train_score - gbm_tuned_test_score).round(4)\n",
    "\n",
    "# saving the AUC score\n",
    "gbm_tuned_auc = roc_auc_score(y_true  = y_test,\n",
    "                                 y_score = full_gbm_default_pred).round(4) # auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646ea84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unpacking the confusion matrix\n",
    "gbm_tuned_tn, \\\n",
    "gbm_tuned_fp, \\\n",
    "gbm_tuned_fn, \\\n",
    "gbm_tuned_tp = confusion_matrix(y_true = y_test, y_pred = full_gbm_default_pred).ravel()\n",
    "\n",
    "\n",
    "# printing each result one-by-one\n",
    "print(f\"\"\"\n",
    "True Negatives : {gbm_tuned_tn}\n",
    "False Positives: {gbm_tuned_fp}\n",
    "False Negatives: {gbm_tuned_fn}\n",
    "True Positives : {gbm_tuned_tp}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77984248",
   "metadata": {},
   "outputs": [],
   "source": [
    "# printing the final scores\n",
    "print(f\"\"\"\n",
    "Model                    AUC Score    Train Score    Test Score   Train-Test Gap   TN, FP, FN, TP\n",
    "-----                   -----------   -----------    ----------   ------------      --------------\n",
    "Logistic                 {logreg_auc_score}       {logreg_train_score}          {logreg_test_score}       {logreg_test_gap}          {logreg_tn, logreg_fp, logreg_fn, logreg_tp}\n",
    "Tuned LR                 {lr_tuned_auc}       {lr_tuned_train_score}          {lr_tuned_test_score}       {logreg_test_gap}          {lr_tuned_tn, lr_tuned_fp,lr_tuned_fn, lr_tuned_tp }\n",
    "Full Tree [Final model]  {full_tree_auc_score}       {full_tree_train_score}          {full_tree_test_score}       {full_tree_test_gap}          {full_tree_tn, full_tree_fp, full_tree_fn, full_tree_tp}\n",
    "Tuned Tree               {tree_tuned_auc}       {tree_tuned_train_score}          {tree_tuned_test_score}       {tree_tuned_test_gap}          {tuned_tree_tn, tuned_tree_fp, tuned_tree_fn, tuned_tree_tp}\n",
    "Pruned Tree              {pruned_tree_auc_score}         {pruned_tree_train_score}           {pruned_tree_test_score}       {pruned_tree_test_gap}          {pruned_tree_tn, pruned_tree_fp, pruned_tree_fn, pruned_tree_tp}\n",
    "KNN                      {knn_auc_score}       {knn_train_score}          {knn_test_score}        {knn_test_gap}          {knn_tree_tn,knn_tree_fp, knn_tree_fn, knn_tree_tp}\n",
    "Random Forest            {rf_auc_score}         {rf_train_score}           {rf_test_score}        {rf_test_gap}            {rf_tn, rf_fp, rf_fn, rf_tp}\n",
    "Tuned RF                 {forest_tuned_auc}       {forest_tuned_train_score}          {forest_tuned_test_score}       {forest_tuned_test_gap}          {tuned_rf_tn, tuned_rf_fp, tuned_rf_fn, tuned_rf_tp}\n",
    "GBM                      {gbm_auc}       {gbm_train_acc}          {gbm_test_acc}       {gbm_test_gap}          {gbm_default_tn, gbm_default_fp, gbm_default_fn, gbm_default_tp}\n",
    "Tuned GBM                {gbm_tuned_auc}       {gbm_tuned_train_score}          {gbm_tuned_test_score}       {gbm_tuned_test_gap}           {gbm_tuned_tn,gbm_tuned_fp,gbm_tuned_fn, gbm_tuned_tp }\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": "",
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "288px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
