{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea36f65e",
   "metadata": {},
   "source": [
    "<h1> Unsupervised Analysis Project </h1>\n",
    "\n",
    "The following analysis will be performed in order to generate actionable recommendations for the marketing department as an strategy to increase and retain the total amount of active users after analyzing the data of user's downloading behavior, and giving them insights to target consumers more efficiently. <br>\n",
    "\n",
    "Our main insights are further explained through the analysis, and a summary is provided below according to the clusters that were created:<br>\n",
    "\n",
    "- The first cluster should be targeted with adverting related to the company's app on social media, entertaining, and gaming apps as well as on Facebook website.\n",
    "- For the second cluster they should focus more on advertising apps on Facebook and Youtube since the majority of the users are millenials.\n",
    "- The third cluster should be targeted via Youtube website as well as on gaming and social media apps. \n",
    "- For the fourth cluster the marketing departing should advertise heavily on free apps related to music and gaming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7970ca52",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################\n",
    "# importing packages\n",
    "##########################################\n",
    "import numpy             as np                   # mathematical essentials\n",
    "import pandas            as pd                   # data science essentials\n",
    "import matplotlib.pyplot as plt                  # fundamental data visualization\n",
    "import seaborn           as sns                  # enhanced visualization\n",
    "\n",
    "# packages for unsupervised learning\n",
    "from sklearn.preprocessing   import StandardScaler      # standard scaler\n",
    "from sklearn.decomposition   import PCA                 # pca\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage # dendrograms\n",
    "from sklearn.cluster         import KMeans              # k-means clustering\n",
    "\n",
    "##########################################\n",
    "# loading data and setting display options\n",
    "##########################################\n",
    "# loading data\n",
    "app_df = pd.read_excel('./Mobile_App_Survey_Data.xlsx')\n",
    "\n",
    "# setting print options\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "\n",
    "#app_df.head(n = 5)\n",
    "\n",
    "# analyzing the dataframe\n",
    "#app_df.describe().round(decimals = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3249bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################\n",
    "# loading user defined functions\n",
    "##########################################\n",
    "\n",
    "########################\n",
    "# scree_plot           #\n",
    "########################\n",
    "def scree_plot(pca_object, export = False):\n",
    "    \"\"\"\n",
    "    Visualizes a scree plot from a pca object.\n",
    "    \n",
    "    PARAMETERS\n",
    "    ----------\n",
    "    pca_object | A fitted pca object\n",
    "    export     | Set to True if you would like to save the scree plot to the\n",
    "               | current working directory (default: False)\n",
    "    \"\"\"\n",
    "    # building a scree plot\n",
    "\n",
    "    # setting plot size\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    features = range(pca_object.n_components_)\n",
    "\n",
    "\n",
    "    # developing a scree plot\n",
    "    plt.plot(features,\n",
    "             pca_object.explained_variance_ratio_,\n",
    "             linewidth = 2,\n",
    "             marker = 'o',\n",
    "             markersize = 10,\n",
    "             markeredgecolor = 'black',\n",
    "             markerfacecolor = 'grey')\n",
    "\n",
    "\n",
    "    # setting more plot options\n",
    "    plt.title('Scree Plot')\n",
    "    plt.xlabel('PCA feature')\n",
    "    plt.ylabel('Explained Variance')\n",
    "    plt.xticks(features)\n",
    "\n",
    "    if export == True:\n",
    "    \n",
    "        # exporting the plot\n",
    "        plt.savefig('./__analysis_images/top_customers_correlation_scree_plot.png')\n",
    "        \n",
    "    # displaying the plot\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "########################\n",
    "# unsupervised_scaler  #\n",
    "########################\n",
    "def unsupervised_scaler(df):\n",
    "    \"\"\"\n",
    "    Standardizes a dataset (mean = 0, variance = 1). Returns a new DataFrame.\n",
    "    Requires sklearn.preprocessing.StandardScaler()\n",
    "    \n",
    "    PARAMETERS\n",
    "    ----------\n",
    "    df     | DataFrame to be used for scaling\n",
    "    \"\"\"\n",
    "\n",
    "    # INSTANTIATING a StandardScaler() object\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "\n",
    "    # FITTING the scaler with the data\n",
    "    scaler.fit(df)\n",
    "\n",
    "\n",
    "    # TRANSFORMING our data after fit\n",
    "    x_scaled = scaler.transform(df)\n",
    "\n",
    "    \n",
    "    # converting scaled data into a DataFrame\n",
    "    new_df = pd.DataFrame(x_scaled)\n",
    "\n",
    "\n",
    "    # reattaching column names\n",
    "    new_df.columns = df.columns\n",
    "    \n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61f5367",
   "metadata": {},
   "source": [
    "<h1>Creating Data Frames</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9045c2dc",
   "metadata": {},
   "source": [
    "The principal component analysis, should only include psychometric features, therefore a new DataFrame will be created including the results from questions 24, 25 and 26. In addition, two more DataFrame will be created to group demographic and usage behavior features , as later demographic and behavior data will be used to compare results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f27bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating dataframes for each psychometric features\n",
    "app_behavior_24 = pd.DataFrame(app_df.loc[ : , 'q24r1':'q24r12' ])\n",
    "app_behavior_25 = pd.DataFrame(app_df.loc[ : , 'q25r1':'q25r12' ])\n",
    "app_behavior_26 = pd.DataFrame(app_df.loc[ : , 'q26r18':'q26r17'])\n",
    "\n",
    "\n",
    "# creating dataframes for demographic features\n",
    "app_demo = pd.concat([app_df.loc[ : , 'q1'], app_df.loc[ : , 'q48':'q57']], \n",
    "                     axis = 1)\n",
    "\n",
    "\n",
    "# creating dataframes for behavior features\n",
    "app_usage = pd.DataFrame(app_df.loc[ : ,'q2r1':'q13r12'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1ab680",
   "metadata": {},
   "source": [
    "<h1>Analyzing psychometric data from question 24</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c1bc4d5",
   "metadata": {},
   "source": [
    "We transposed the psychometric DataFrames and scaled them since we want to make sure that people that have really strong and different opinions from the average are statistically treated equally in the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69007fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first transposing for question 24 DataFrame\n",
    "app_behavior_24_transposed = app_behavior_24.transpose()\n",
    "\n",
    "# first applying the unsupervised_scaler function to question 24 DataFrame\n",
    "app_scaled_24_tran = unsupervised_scaler(df = app_behavior_24_transposed)\n",
    "\n",
    "\n",
    "# second transposing for question 24 DataFrame\n",
    "app_24_tech = app_scaled_24_tran.transpose()\n",
    "\n",
    "# naming columns as orignal features\n",
    "app_24_tech.columns = app_behavior_24.columns\n",
    "\n",
    "# second applying the unsupervised_scaler function to question 24 DataFrame\n",
    "app_24_tech_scaled = unsupervised_scaler(df = app_24_tech)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a464974",
   "metadata": {},
   "source": [
    "<h2> Principal Component Analysis </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f561fe74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiating a PCA object with no limit to principal components\n",
    "pca_24 = PCA(n_components = None,\n",
    "             random_state = 219)\n",
    "\n",
    "# Fitting and transforming the scaled data\n",
    "app_pca_24 = pca_24.fit_transform(app_24_tech_scaled)\n",
    "\n",
    "# comparing dimensions of each DataFrame\n",
    "#print(\"Original shape:\", app_24_tech_scaled.shape)\n",
    "#print(\"PCA shape     :\", app_pca_24.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603336fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# component number counter\n",
    "component_number    = 0\n",
    "cumulative_variance = 0\n",
    "\n",
    "# looping over each principal component\n",
    "for variance in pca_24.explained_variance_ratio_:\n",
    "    component_number    += 1\n",
    "    cumulative_variance += variance\n",
    "\n",
    "#    print(f\"\"\"\n",
    "#PC:                  {component_number}\n",
    "#Percentage Variance: {variance.round(3)}\n",
    "#Cumulative Variance: {cumulative_variance.round(3)}\"\"\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f0926d",
   "metadata": {},
   "source": [
    "<h2> Optimal number of PCA </h2>\n",
    "\n",
    "With a visual analysis, we determined the optimal number of PCAs comparing two visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa77ca26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calling scree_plot function\n",
    "scree_plot(pca_object = pca_24, \n",
    "           export     = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9390656f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiating new model using optimal number of principal components\n",
    "pca_24_2 = PCA(n_components = 2,\n",
    "               random_state = 219)\n",
    "\n",
    "# Fitting and transforming question 24 scaled data\n",
    "app_pca_24_2 = pca_24_2.fit_transform(app_24_tech_scaled)\n",
    "\n",
    "# calling scree_plot function\n",
    "scree_plot(pca_object = pca_24_2,\n",
    "           export     = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad379ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# component number counter\n",
    "component_number    = 0\n",
    "cumulative_variance = 0\n",
    "\n",
    "# looping over each principal component\n",
    "for variance in pca_24_2.explained_variance_ratio_:\n",
    "    component_number    += 1\n",
    "    cumulative_variance += variance\n",
    "    \n",
    "    #checking variances\n",
    "    print(f\"\"\"\n",
    "PC:                  {component_number}\n",
    "Percentage Variance: {variance.round(3)}\n",
    "Cumulative Variance: {cumulative_variance.round(3)}\"\"\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f634f98e",
   "metadata": {},
   "source": [
    "<h2> Interpretation and Persona Development </h2>\n",
    "\n",
    "There are several groups classified in the survey that gather data to decide which customers to target according to user behavior. We created groups of tech savvy and not tech savvy people customers, leaders, optimistic, groups that avoid luxury brands and freemium users. <br>\n",
    "\n",
    "- For tech savvy, since they already enjoy technology and being updated with new apps, therefore the marketing department should focus their strategies on these type of persona, and take advantage of their technology usage behavior.<br>\n",
    "\n",
    "- For the not tech savvy, we separated them according to their skepticism to the use of technology and their preference of not using social media platforms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d9608f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transposing optimal number pca components\n",
    "factor_loadings_24_2 = pd.DataFrame(np.transpose(pca_24_2.components_))\n",
    "\n",
    "# naming rows as original features\n",
    "factor_loadings_24_2 = factor_loadings_24_2.set_index(app_24_tech_scaled.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84fe82c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# naming principal components\n",
    "factor_loadings_24_2.columns = ['Technology savvy', # embraces technology\n",
    "                                'Not technology savvy'] # avoid  technology\n",
    "\n",
    "# checking the result\n",
    "factor_loadings_24_2.round(decimals = 2)\n",
    "\n",
    "# saving to Excel for analysis\n",
    "#factor_loadings_24_2.to_excel('factor_loadings_24.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0667e1",
   "metadata": {},
   "source": [
    "<h1>Analyzing psychometric data from question 25</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769243a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first transposing for question 25 DataFrame\n",
    "app_behavior_25_transposed = app_behavior_25.transpose()\n",
    "\n",
    "# first applying the unsupervised_scaler function to question 25 DataFrame\n",
    "app_scaled_25_tran = unsupervised_scaler(df = app_behavior_25_transposed)\n",
    "\n",
    "\n",
    "# second transposing for question 25 DataFrame\n",
    "app_25_tech = app_scaled_25_tran.transpose()\n",
    "\n",
    "# naming columns as orignal features\n",
    "app_25_tech.columns = app_behavior_25.columns\n",
    "\n",
    "# second applying the unsupervised_scaler function to question 25 DataFrame\n",
    "app_25_tech_scaled = unsupervised_scaler(df = app_25_tech)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7fd135a",
   "metadata": {},
   "source": [
    "<h2> Principal Component Analysis </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137dceb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiating a PCA object with no limit to principal components\n",
    "pca_25 = PCA(n_components = None,\n",
    "            random_state = 219)\n",
    "\n",
    "# Fitting and transforming the scaled data\n",
    "app_pca_25 = pca_25.fit_transform(app_25_tech_scaled)\n",
    "\n",
    "# comparing dimensions of each DataFrame\n",
    "#print(\"Original shape:\", app_25_tech_scaled.shape)\n",
    "#print(\"PCA shape     :\", app_pca_25.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df584f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# component number counter\n",
    "component_number    = 0\n",
    "cumulative_variance = 0\n",
    "\n",
    "# looping over each principal component\n",
    "for variance in pca_25.explained_variance_ratio_:\n",
    "    component_number    += 1\n",
    "    cumulative_variance += variance\n",
    "    \n",
    "#    print(f\"\"\"\n",
    "#PC:                  {component_number}\n",
    "#Percentage Variance: {variance.round(3)}\n",
    "#Cumulative Variance: {cumulative_variance.round(3)}\"\"\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e3889b5",
   "metadata": {},
   "source": [
    "<h2> Optimal number of PCA </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d907a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calling scree_plot function\n",
    "scree_plot(pca_object = pca_25,\n",
    "           export     = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc85939",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiating new model using optimal number of principal components\n",
    "pca_25_2 = PCA(n_components = 2,\n",
    "               random_state = 219)\n",
    "\n",
    "# Fitting and transforming question 25 scaled data\n",
    "app_pca_25_2 = pca_25_2.fit_transform(app_25_tech_scaled)\n",
    "\n",
    "\n",
    "# calling scree_plot function\n",
    "scree_plot(pca_object = pca_25_2,\n",
    "           export     = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa66633",
   "metadata": {},
   "outputs": [],
   "source": [
    "# component number counter\n",
    "component_number    = 0\n",
    "cumulative_variance = 0\n",
    "\n",
    "# looping over each principal component\n",
    "for variance in pca_25_2.explained_variance_ratio_:\n",
    "    component_number    += 1\n",
    "    cumulative_variance += variance\n",
    "    \n",
    "    #checking variances\n",
    "    print(f\"\"\"\n",
    "PC:                  {component_number}\n",
    "Percentage Variance: {variance.round(3)}\n",
    "Cumulative Variance: {cumulative_variance.round(3)}\"\"\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df2c74ea",
   "metadata": {},
   "source": [
    "<h2> Interpretation and Persona Development </h2>\n",
    "\n",
    "- For the leader persona, they tend to be more competitive than the average people and their behavior is not influenced by other people's opinions. In addition, when it comes to purchase decisions, they are more inclined towards following their inner instinct and knowledge. They may perhaps look like a more difficult kind of customer to approach.<br>\n",
    "\n",
    "- On the other hand, we have optimistic people, which may tend to be more willing to accept deals and buy new products given their stronger condescending nature. Usually, they also are the ones who are more brand loyal, because they would rather follow somebody else's higher competency in a field (like a big company's way of doing business) than by doing some research by themselves; for these reasons they may be an easier target for new products entering the market.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b05c9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transposing optimal number pca components\n",
    "factor_loadings_25_2 = pd.DataFrame(np.transpose(pca_25_2.components_))\n",
    "\n",
    "# naming rows as original features\n",
    "factor_loadings_25_2 = factor_loadings_25_2.set_index(app_25_tech_scaled.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df1182b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# naming principal components\n",
    "factor_loadings_25_2.columns = ['Leader',\n",
    "                                'Optimistic']\n",
    "\n",
    "# checking the result\n",
    "factor_loadings_25_2.round(decimals = 2)\n",
    "\n",
    "# saving to Excel\n",
    "#factor_loadings_25_2.to_excel('factor_loadings_25.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f59473",
   "metadata": {},
   "source": [
    "<h1>Analyzing psychometric data from question 26</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee660d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first transposing for question 26 DataFrame\n",
    "app_behavior_26_transposed = app_behavior_26.transpose()\n",
    "\n",
    "# first applying the unsupervised_scaler function to question 26 DataFrame\n",
    "app_scaled_26_tran = unsupervised_scaler(df = app_behavior_26_transposed)\n",
    "\n",
    "\n",
    "# second transposing for question 25 DataFrame\n",
    "app_26_tech = app_scaled_26_tran.transpose()\n",
    "\n",
    "# naming columns as orignal features\n",
    "app_26_tech.columns = app_behavior_26.columns\n",
    "\n",
    "# second applying the unsupervised_scaler function to question 26 DataFrame\n",
    "app_26_tech_scaled = unsupervised_scaler(df = app_26_tech)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a56751",
   "metadata": {},
   "source": [
    "## Principal Component Analysis and Scaling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee5a3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiating a PCA object with no limit to principal components\n",
    "pca_26 = PCA(n_components = None,\n",
    "            random_state = 219)\n",
    "\n",
    "# Fitting and transforming the scaled data\n",
    "app_pca_26 = pca_26.fit_transform(app_26_tech_scaled)\n",
    "\n",
    "# comparing dimensions of each DataFrame\n",
    "print(\"Original shape:\", app_26_tech_scaled.shape)\n",
    "print(\"PCA shape     :\", app_pca_26.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ef2f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# component number counter\n",
    "component_number = 0\n",
    "\n",
    "# looping over each principal component\n",
    "for variance in pca_26.explained_variance_ratio_:\n",
    "    component_number += 1\n",
    "    \n",
    "    print(f\"PC {component_number}: {variance.round(3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25393736",
   "metadata": {},
   "outputs": [],
   "source": [
    "# component number counter\n",
    "component_number    = 0\n",
    "cumulative_variance = 0\n",
    "\n",
    "# looping over each principal component\n",
    "for variance in pca_26.explained_variance_ratio_:\n",
    "    component_number    += 1\n",
    "    cumulative_variance += variance\n",
    "#    print(f\"\"\"\n",
    "#PC:                  {component_number}\n",
    "#Percentage Variance: {variance.round(3)}\n",
    "#Cumulative Variance: {cumulative_variance.round(3)}\"\"\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380e253a",
   "metadata": {},
   "source": [
    "### Evaluation of PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ff7bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "scree_plot (pca_object  = pca_26,\n",
    "            export = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312fc1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transposing pca components\n",
    "factor_loadings_df_26 = pd.DataFrame(np.transpose(pca_26.components_.round(decimals = 2)))\n",
    "\n",
    "# naming rows as original features\n",
    "factor_loadings_df_26 = factor_loadings_df_26.set_index(app_26_tech_scaled.columns)\n",
    "\n",
    "# saving to Excel\n",
    "#factor_loadings_df_26.to_excel('app_factor_loadings_26.xlsx')\n",
    "\n",
    "#factor_loadings_df_26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44520361",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiating a new model using the first two principal components\n",
    "pca_26_2 = PCA(n_components = 2,\n",
    "            random_state = 219)\n",
    "\n",
    "\n",
    "# Fitting and transforming the app scaled\n",
    "app_pca_26_2 = pca_26_2.fit_transform(app_26_tech_scaled)\n",
    "\n",
    "\n",
    "# calling the scree_plot function\n",
    "scree_plot(pca_object = pca_26_2,\n",
    "           export     = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1b8ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting plot size\n",
    "#fig, ax = plt.subplots(figsize = (12, 3))\n",
    "\n",
    "\n",
    "# developing a PC to feature heatmap\n",
    "#sns.heatmap(pca_26_2.components_, \n",
    "#            cmap = 'coolwarm',\n",
    "#            square = True,\n",
    "#            annot = True,\n",
    "#            linewidths = 0.1,\n",
    "#            linecolor = 'black')\n",
    "\n",
    "\n",
    "# setting more plot options\n",
    "#plt.yticks([0, 1],\n",
    "#           [\"PC 1\", \"PC 2\"])\n",
    "\n",
    "#plt.xticks(range(0, 16),\n",
    "#           app_26_tech_scaled.columns,\n",
    "#           rotation=60,\n",
    "#           ha='left')\n",
    "\n",
    "#plt.xlabel(xlabel = \"Feature\")\n",
    "#plt.ylabel(ylabel = \"Principal Component\")\n",
    "\n",
    "\n",
    "# displaying the plot\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80945a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# component number counter\n",
    "component_number    = 0\n",
    "cumulative_variance = 0\n",
    "\n",
    "# looping over each principal component\n",
    "for variance in pca_26_2.explained_variance_ratio_:\n",
    "    component_number    += 1\n",
    "    cumulative_variance += variance\n",
    "    print(f\"\"\"\n",
    "PC:                  {component_number}\n",
    "Percentage Variance: {variance.round(3)}\n",
    "Cumulative Variance: {cumulative_variance.round(3)}\"\"\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ec0dd7",
   "metadata": {},
   "source": [
    "<h2> Interpretation and Persona Development </h2>\n",
    "\n",
    "- For the third psychometric variable, we classified the first persona as \"avoids luxury brands\" because this would be a person that prefers to buy more affordable brands and abstain from luxury brands. This target group could be more difficult to reach since they usually don't spend that much money.\n",
    "\n",
    "- The second persona was classified as a Freemium user because they lean toward discounts and prefer not to spend a lot of money on apps. They don't download that many apps and they believe it's not worth it to spend money to get better app features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c0cbe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transposing pca components (pc = 2)\n",
    "factor_loadings_26_2 = pd.DataFrame(np.transpose(pca_26_2.components_))\n",
    "\n",
    "\n",
    "# naming rows as original features\n",
    "factor_loadings_26_2 = factor_loadings_26_2.set_index(app_26_tech_scaled.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b358be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# naming each principal component\n",
    "factor_loadings_26_2.columns = ['Avoids luxury brands',\n",
    "                                'Freemium user']\n",
    "\n",
    "factor_loadings_26_2.round(decimals = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7955c7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving to Excel\n",
    "#factor_loadings_26_2.to_excel('factor_loadings_26.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e928db",
   "metadata": {},
   "source": [
    "Analysis of the factor loading for each customer to develop a strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b798bcf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyzing factor strengths per customer\n",
    "factor_load24 = pca_24_2.transform(app_24_tech_scaled)\n",
    "\n",
    "# converting to a DataFrame\n",
    "factor_load_df_24 = pd.DataFrame(factor_load24)\n",
    "\n",
    "# renaming columns\n",
    "factor_load_df_24.columns = factor_loadings_24_2.columns\n",
    "\n",
    "factor_load_df_24.head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d5a2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyzing factor strengths per customer\n",
    "factor_load25 = pca_25_2.transform(app_25_tech_scaled)\n",
    "\n",
    "# converting to a DataFrame\n",
    "factor_load_df_25 = pd.DataFrame(factor_load25)\n",
    "\n",
    "# renaming columns\n",
    "factor_load_df_25.columns = factor_loadings_25_2.columns\n",
    "\n",
    "factor_load_df_25.head(n=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7420aa5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyzing factor strengths per customer\n",
    "factor_load26 = pca_26_2.transform(app_26_tech_scaled)\n",
    "\n",
    "# converting to a DataFrame\n",
    "factor_load_df_26 = pd.DataFrame(factor_load26)\n",
    "\n",
    "# renaming columns\n",
    "factor_load_df_26.columns = factor_loadings_26_2.columns\n",
    "\n",
    "factor_load_df_26.head(n=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61684ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exploring customers in the Technology savvy persona\n",
    "len(factor_load_df_24['Technology savvy'][factor_load_df_24['Technology savvy'] > 1.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2cff620",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exploring customers in the Technology savvy persona\n",
    "len(factor_load_df_24['Not technology savvy'][factor_load_df_24['Not technology savvy'] > 1.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1564297d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exploring customers in the Leader persona\n",
    "len(factor_load_df_25['Leader'][factor_load_df_25['Leader'] > 1.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e7df36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exploring customers in the Leader persona\n",
    "len(factor_load_df_25['Optimistic'][factor_load_df_25['Optimistic'] > 1.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89a5352",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exploring customers in the Avoids luxury brands persona\n",
    "len(factor_load_df_26['Avoids luxury brands'][factor_load_df_26['Avoids luxury brands'] > 1.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff58346",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exploring customers in the Leader persona\n",
    "len(factor_load_df_26['Freemium user'][factor_load_df_26['Freemium user'] > 1.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a155f9fc",
   "metadata": {},
   "source": [
    "## Clustering\n",
    "We developed a clustering model to group data with similar treats, we used a dendrogram to show a visual representation of our clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94445e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding the 3 psychometrical together\n",
    "all_factors = pd.concat([factor_load_df_24,factor_load_df_25,factor_load_df_26],axis = 1)\n",
    "\n",
    "# applying the unsupervised_scaler function\n",
    "pca_scaled = unsupervised_scaler(all_factors)\n",
    "\n",
    "# grouping data based on Ward distance\n",
    "standard_mergings_ward = linkage(y = pca_scaled,\n",
    "                                 method = 'ward',\n",
    "                                 optimal_ordering = True)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 12))\n",
    "\n",
    "# developing a dendrogram\n",
    "dendrogram(Z = standard_mergings_ward,\n",
    "           leaf_rotation = 90,\n",
    "           leaf_font_size = 6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c61c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing the candidate number of clusters\n",
    "# Instantiating a k-Means object with five clusters\n",
    "survey_k_pca = KMeans(n_clusters   = 4,\n",
    "                        random_state = 219)\n",
    "\n",
    "\n",
    "# fitting the object to the data\n",
    "survey_k_pca.fit(pca_scaled)\n",
    "\n",
    "\n",
    "# converting the clusters to a DataFrame\n",
    "survey_kmeans_pca = pd.DataFrame({'Cluster': survey_k_pca.labels_})\n",
    "\n",
    "print(survey_kmeans_pca.iloc[: , 0].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff60a4d3",
   "metadata": {},
   "source": [
    "Displaying the mean of each clusters we can develop stories for each group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b14fe9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# storing cluster centers\n",
    "centroids_pca = survey_k_pca.cluster_centers_\n",
    "\n",
    "\n",
    "# converting cluster centers into a DataFrame\n",
    "centroids_pca_df = pd.DataFrame(centroids_pca)\n",
    "\n",
    "# renaming principal components\n",
    "centroids_pca_df.columns = ['Technology savvy',\n",
    "                           'Not technology savvy',\n",
    "                           'Leader',\n",
    "                           'Optimistic',\n",
    "                           'Avoids luxury brands',\n",
    "                           'Freemium user']\n",
    "\n",
    "# checking results (clusters = rows, pc = columns)\n",
    "centroids_pca_df.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae744cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatinating cluster memberships with principal components\n",
    "clst_pca_df = pd.concat([survey_kmeans_pca,\n",
    "                         all_factors],\n",
    "                         axis = 1)\n",
    "\n",
    "# concatenating demographic and behavioral information with pca-clusters\n",
    "final_pca_clust_df = pd.concat([app_demo, app_usage,\n",
    "                                clst_pca_df.round(decimals = 2)],\n",
    "                                axis = 1)\n",
    "# renaming columns\n",
    "final_pca_clust_df.columns = ['Age','Education','Marital status','No children',\n",
    "                             'Children under 6 yrs','Children 6-12 yrs','Children 13-17 yrs',\n",
    "                             'Children >18','Race', 'Hispanic or Latino', 'Income before taxes',\n",
    "                             'Gender','iPhone','iPod touch','Android','BlackBerry','Nokia',\n",
    "                             'Windows','HP','Tablet','Other','None','Music App','TV Check in App',\n",
    "                             'Entretainment App','TV Show App','Gaming App','Social Networking App',\n",
    "                             'News App','Shopping App','Specific News App','Other Apps','No apps',\n",
    "                             'Number of apps','Free apps', 'Facebook','Twitter','Myspace','Pandora radio',\n",
    "                             'Vevo','YouTube','AOL Radio','Last.fm','Yahoo Entertainment and Music',\n",
    "                              'IMBD','LinkedIn','Netflix','Cluster','Technology savvy','Not technology savvy',\n",
    "                             'Leader','Optimistic','Avoids luxury brands','Freemium user']\n",
    "\n",
    "final_pca_clust_df.head(n = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627a583c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#renaiming channels\n",
    "\n",
    "age = {1: 'Under 18',\n",
    "       2: '18-24',\n",
    "       3: '25-29',\n",
    "       4: '30-34',\n",
    "       5: '35-39',\n",
    "       6: '40-44',\n",
    "       7: '45-49',\n",
    "       8: '50-54',\n",
    "       9: '55-59',\n",
    "       10: '60-64',\n",
    "       11: '>65'}\n",
    "final_pca_clust_df['Age'].replace(age, inplace = True)\n",
    "\n",
    "education = {1: 'Some high school',\n",
    "             2: 'High school graduate',\n",
    "             3: 'Some college',\n",
    "             4: 'College graduate',\n",
    "             5: 'Some post-graduate studies',\n",
    "             6: 'Post graduate degree'}\n",
    "final_pca_clust_df['Education'].replace(education, inplace = True)\n",
    "\n",
    "marital_status = {1: 'Married',\n",
    "                  2: 'Single',\n",
    "                  3: 'Single with a partner',\n",
    "                  4: 'Separated/Widowed/ Divorced'}\n",
    "final_pca_clust_df['Marital status'].replace(marital_status, inplace = True)\n",
    "\n",
    "race = {1: 'White/Caucasian',\n",
    "        2: 'Black/African American',\n",
    "        3: 'Asian',\n",
    "        4: 'Native Hawaiian/Pacific Islander',\n",
    "        5: 'American Indian/Alaska Native',\n",
    "        6: 'Other race'}\n",
    "final_pca_clust_df['Race'].replace(race, inplace = True)\n",
    "\n",
    "ethinicity = {1: 'Yes',\n",
    "              2: 'No'}\n",
    "final_pca_clust_df['Hispanic or Latino'].replace(ethinicity, inplace = True)\n",
    "\n",
    "income = {1: 'Under 10k',\n",
    "          2: '10k-15k[' ,\n",
    "          3: '15k-20k[',\n",
    "          4: '20k-30k[',\n",
    "          5: '30k-40k[',\n",
    "          6: '40k-50k[',\n",
    "          7: '50k-60k[',\n",
    "          8: '60k-70k[',\n",
    "          9: '70k-80k[',\n",
    "          10:'80k-90k[',\n",
    "          11: '90k-100k[',\n",
    "          12:'100k-125k[',\n",
    "          13: '125k-150k[',\n",
    "          14: '>150k'}\n",
    "final_pca_clust_df['Income before taxes'].replace(income, inplace = True)\n",
    "\n",
    "cluster_names = {0 : 'Cluster 1',\n",
    "                 1 : 'Cluster 2',\n",
    "                 2 : 'Cluster 3',\n",
    "                 3 : 'Cluster 4'}\n",
    "final_pca_clust_df['Cluster'].replace(cluster_names, inplace = True)\n",
    "\n",
    "data_df = final_pca_clust_df\n",
    "\n",
    "\n",
    "# checking results\n",
    "#data_df.head(n = 5)\n",
    "\n",
    "# saving to Excel\n",
    "#data_df.to_excel('data_df.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82da9b3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#data_df[data_df.loc[ : , 'Cluster'] == 'Cluster 1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0df5b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig, ax = plt.subplots(figsize = (12, 8))\n",
    "#sns.boxplot(x = 'Age',\n",
    "#            y = 'Technology savvy',\n",
    "#            hue = 'Cluster',\n",
    "#            data = data_df)\n",
    "#plt.tight_layout()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a138da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig, ax = plt.subplots(figsize = (12, 8))\n",
    "#sns.boxplot(x = 'Income before taxes',\n",
    "#            y = 'Technology savvy',\n",
    "#            hue = 'Cluster',\n",
    "#            data = data_df)\n",
    "#plt.tight_layout()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c6da64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig, ax = plt.subplots(figsize = (12, 8))\n",
    "#sns.boxplot(x = 'Age',\n",
    "#            y = 'Not technology savvy',\n",
    "#            hue = 'Cluster',\n",
    "#            data = data_df)\n",
    "#plt.tight_layout()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b619cb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig, ax = plt.subplots(figsize = (12, 8))\n",
    "#sns.boxplot(x = 'Income before taxes',\n",
    "#            y = 'Not technology savvy',\n",
    "#            hue = 'Cluster',\n",
    "#            data = data_df)\n",
    "#plt.tight_layout()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a87ad3",
   "metadata": {},
   "source": [
    "<h1>Final analysis with Demographic variables</h1>\n",
    "\n",
    "After dividing our data in four clusters, we can see some tendencies which will help the marketing department develop strategies to target these groups for more app downloading.<br>\n",
    "\n",
    "<h2>Cluster 1</h2>\n",
    "\n",
    "Cluster 1 mainly includes White/Caucasian young people between the ages of 18 and 24 years old who are still in collage or have already completed a college degree, most likely do not have children; this cluster earn on average more than 150k annualy, however they are not inclined toward acquiring luxury brand products as this type of persona is not common whihin the cluster.<br>\n",
    "\n",
    "In addition, this cluster mostly includes the type of persona that avoids luxury brands and are more skeptical with use their data in technological and digital platforms. This cluster is a regular visitor of Facebook, and it is very unlikely that they will visit websites like MySpace and Vevo. However, they do not show a strong behavior toward Netflix, as 32% of the observations are regular visitor and 37% of the participants regale visit the website.Finally, this cluster are avid users of music, gaming, social media apps, and do not show a clear trend toward the usage of entertaining, news, and shopping apps.<br> \n",
    "\n",
    "In this sense, it is recommended that the Marketing team creates a strategy to targets this cluster in case that the Company’s app is not luxury brand or tech related or if it falls into the category of music, gaming, social media apps with mobile support. If the criteria explained before is met, then it would be strongly advised to create a campaign advertising the company’s app on other social media apps as well as in Facebook as to increase the number of users; in addition, it should be developed app features meant to retain and create a loyal engagement with said users as a measure to strength the marketing strategy stated above.\n",
    "<br><br>\n",
    "\n",
    "<h2>Cluster 2</h2>\n",
    "\n",
    "Cluster 2 has mostly people from 18 to 29 years old, with an income between 40k to 60k and they are mostly white with no children, these group is willing to spend money on technology since they have more paid apps downloaded in their devices compared to other customers. <br>\n",
    "\n",
    "These type of cluster would fall into the category of millenials, which are willing to spend money in new technology as well as in luxury and designer brands. This cluster uses mostly social media, music and gaming apps.<br>\n",
    "\n",
    "The marketing department should focus more on advertising apps on Facebook and Youtube, since it is the one the majority of the people in the cluster uses. If they advertise apps via these platforms, there are more chances of people paying for the apps.\n",
    "<br><br> \n",
    "\n",
    "\n",
    "<h2>Cluster 3</h2>\n",
    "\n",
    "For cluster 3 on average their age range from 18 to 34 years old, are mostly tech savvy type of persona, they earn between 30k to 60k annually and are most likely White/Caucasian, and they are predominantly married without children. Additionally, they are probably people that are more conscious about their expenir income is low and probably that could be the reason they decide not to have children.<br>  \n",
    "\n",
    "This segment of people is a little bit older but they tend to enjoy technology, and usually have a leader personality, they are not freemium users, neither optimistic nor use apps for entertainment, and we identified that most of them frequently use Facebook and YouTube websites. <br> <br>\n",
    "\n",
    "The recommendation for this cluster would be to target them via Youtube, but start to add more weight on paid apps that have to do with entertainment because this could make them prone to have more experiences and would be willing to pay more for new apps. If the apps are related to specific news or TV related apps, this cluster should not be targeted at all.<br> <br> \n",
    "\n",
    "\n",
    "\n",
    "<h2>Cluster 4</h2>\n",
    "\n",
    "Based on our analysis, cluster 4 includes ages ranging between 18-29 years old and it is highly presumably that are single, and  on average earn between 20k to 50k annually. This cluster is likely the type of persona defined as tech savvy as well as leaders.<br>  \n",
    "\n",
    "In addition they are regular users of free apps as they are available at no cost for the user and most likely include adds on them. They are engaged the Facebook social medial platform, however, do not show a strong trend for the usage of Twitter or Netflix website. Yet within the same age groups, they avoid luxury brands as they don't have the means to spend on this type of products.<br>  \n",
    "\n",
    "With their highly engaged social media presence, the marketing departing should advertise heavily on free apps related to music and gaming in addition to create a separate strategy to target the conversion of those users that are not active on entertaining, news and shopping apps."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": "1",
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
